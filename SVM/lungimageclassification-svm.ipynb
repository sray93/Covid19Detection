{"cells":[{"metadata":{},"cell_type":"markdown","source":"SVM implementation for Lung Image Classification"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#importing relevant libraries required for code execution\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport os\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\n%matplotlib inline\nfrom PIL import Image\nfrom skimage.feature import hog\nfrom skimage.color import rgb2grey\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.ensemble import BaggingClassifier ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install imutils\nimport imutils","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defining the functions to extract features from the images"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#creating feature vector from pixel values by resizing size\ndef image_to_feature_vector(image, size=(32, 32)):\n    return cv2.resize(image, size).flatten()\n#creating feature vector from color histogram\ndef extract_color_histogram(image, bins=(8, 8, 8)):\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins,[0, 180, 0, 256, 0, 256])\n    if imutils.is_cv2():\n        hist = cv2.normalize(hist)\n    else:\n        cv2.normalize(hist, hist)\n    return hist.flatten() # return the flattened histogram as the feature vector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating imagePath array by concatenating paths of all images\nimagePaths = []\n\nfor dirname, _, filenames in os.walk('/kaggle/input/covid19-radiography-database/COVID-19 Radiography Database/'):\n    for filename in filenames:\n        if (filename[-3:] == 'png'):\n            imagePaths.append(os.path.join(dirname, filename))\n\n#Checking to validate all imagePaths have been included\nlen(imagePaths) == 219+1341+1345","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining the arrays to store the feature vectors and labels\nrawImages = []\nfeatures = []\nlabels = []\nimg=[]\n\nfor imagePath in imagePaths:\n    label = imagePath.split(os.path.sep)[-2]\n    image = cv2.imread(imagePath)\n    pixels = image_to_feature_vector(image) #function call to first feature extraction method\n    hist = extract_color_histogram(image)\n    rawImages.append(pixels) #first feature vector\n    features.append(hist) #second feature vector\n    labels.append(label)\n    img.append(image)\n    \nrawImages = np.array(rawImages)\nfeatures = np.array(features)\nlabels = np.array(labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking model performance with color histogram features with 5-fold cross validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.DataFrame(features)\ny = pd.Series(labels)\nsvm = SVC(kernel='linear', probability=True, random_state=42) #defining the model\ncv = KFold(n_splits=5, random_state=1, shuffle=True) #5-fold cross validation setup\nrecall = cross_val_score(svm, X, y, scoring='recall_macro', cv=cv) #calculating recall \nprint(\"Recall: \",np.mean(recall))\nprecision = cross_val_score(svm, X, y, scoring='precision_macro', cv=cv) #calculating precision\nprint(\"Precision: \",np.mean(precision))\naccuracy = cross_val_score(svm, X, y, scoring='accuracy', cv=cv) #calculating accuracy\nprint(\"Accuracy: \",np.mean(accuracy))\nf1score = cross_val_score(svm, X, y, scoring='f1_macro', cv=cv) #calculating f1score\nprint(\"F1 Score: \",np.mean(f1score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting the model performance metrics \nsvm_metrics = ['Accuracy', 'Recall', 'Precision', 'F1-Score']\nsvm_metric_values = [np.mean(accuracy), np.mean(recall), np.mean(precision), np.mean(f1score)]\nsvm_pos = [i for i, _ in enumerate(svm_metrics)]\nplt.bar(svm_pos, svm_metric_values , color='green')\nplt.xlabel(\"Percentage values\")\nplt.ylabel(\"Metrics\")\nplt.title(\"Performance metrics for SVM\")\nplt.xticks(svm_pos, svm_metrics)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking model performance with pixel intensity as features with 5-fold cross validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.DataFrame(rawImages)\ny = pd.Series(labels)\n# define support vector classifier\nsvm = SVC(kernel='linear', probability=True, random_state=42)\ncv = KFold(n_splits=5, random_state=1, shuffle=True)\nrecall = cross_val_score(svm, X, y, scoring='recall_macro', cv=cv)\nprint(\"Recall: \",np.mean(recall))\nprecision = cross_val_score(svm, X, y, scoring='precision_macro', cv=cv)\nprint(\"Precision: \",np.mean(precision))\naccuracy = cross_val_score(svm, X, y, scoring='accuracy', cv=cv)\nprint(\"Accuracy: \",np.mean(accuracy))\nf1score = cross_val_score(svm, X, y, scoring='f1_macro', cv=cv)\nprint(\"F1 Score: \",np.mean(f1score))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting the model performance metrics \nsvm_metrics = ['Accuracy', 'Recall', 'Precision', 'F1-Score']\nsvm_metric_values = [np.mean(accuracy), np.mean(recall), np.mean(precision), np.mean(f1score)]\nsvm_pos = [i for i, _ in enumerate(svm_metrics)]\nplt.bar(svm_pos, svm_metric_values , color='gray')\nplt.xlabel(\"Percentage values\")\nplt.ylabel(\"Metrics\")\nplt.title(\"Performance metrics for SVM without bagging\")\nplt.xticks(svm_pos, svm_metrics)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking model performance with pixel intensity as features with 5-fold cross validation and bagging with 5 estimators"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.DataFrame(rawImages)\ny = pd.Series(labels)\n# define support vector classifier\nsvm = SVC(kernel='linear', probability=True, random_state=42)\ncv = KFold(n_splits=5, random_state=1, shuffle=True)\nsvm = BaggingClassifier(base_estimator=svm, n_estimators=5, random_state=314) #defining the model with bagging\nrecall = cross_val_score(svm, X, y, scoring='recall_macro', cv=cv)\nprint(\"Recall: \",np.mean(recall))\nprecision = cross_val_score(svm, X, y, scoring='precision_macro', cv=cv)\nprint(\"Precision: \",np.mean(precision))\naccuracy = cross_val_score(svm, X, y, scoring='accuracy', cv=cv)\nprint(\"Accuracy: \",np.mean(accuracy))\nf1score = cross_val_score(svm, X, y, scoring='f1_macro', cv=cv)\nprint(\"F1 Score: \",np.mean(f1score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_metrics = ['Accuracy', 'Recall', 'Precision', 'F1-Score']\nsvm_metric_values = [np.mean(accuracy), np.mean(recall), np.mean(precision), np.mean(f1score)]\nsvm_pos = [i for i, _ in enumerate(svm_metrics)]\nplt.bar(svm_pos, svm_metric_values, color='green')\nplt.xlabel(\"Percentage values\")\nplt.ylabel(\"Metrics\")\nplt.title(\"Performance metrics for SVM with bagging\")\n\nplt.xticks(svm_pos, svm_metrics)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Evaluating model with different values of K for K-Fold cross validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"splits = [x for x in range(2,7)] # define the folds for cross-validation\n#create empty arrays to store the model evaluation metrics\nrecall_final = [] \nprecision_final = []\naccuracy_final = []\nf1_final = []\n\n#training and testing the model for different values of K between 2 and 6\nfor split in splits: \n    cv = KFold(n_splits=split, random_state=1, shuffle=True)\n    recall = cross_val_score(svm, X, y, scoring='recall_macro', cv=cv)\n    recall_final.append(np.mean(recall))\n    precision = cross_val_score(svm, X, y, scoring='precision_macro', cv=cv)\n    precision_final.append(np.mean(precision))\n    accuracy = cross_val_score(svm, X, y, scoring='accuracy', cv=cv)\n    accuracy_final.append(np.mean(accuracy))\n    f1score = cross_val_score(svm, X, y, scoring='f1_macro', cv=cv)\n    f1_final.append(np.mean(f1score))\nprint(\"Recall: \",recall_final)\nprint(\"Precision: \",precision_final)\nprint(\"Accuracy: \",accuracy_final)\nprint(\"F1 Score: \",f1_final)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting the model performance metrics for different values of K \nfig2 = plt.figure(figsize =(12, 7))\nplt.plot(splits,recall_final, label='recall')\nplt.plot(splits,precision_final, label='precision')\nplt.plot(splits,accuracy_final, label='accuracy')\nplt.plot(splits,f1_final, label='f1score')\nplt.xlabel('Folds')\nplt.ylabel('Model Evaluation Metrics')\nplt.title('SVM performance obtained at different folds ')\nplt.legend(loc='lower right')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}